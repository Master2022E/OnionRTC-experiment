{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bandwidth data extraction\n",
    "\n",
    "The data is stored in the Prometheus and this script will query prometheus for the specific time slots were a successful call were done, calculate the average used bandwidth and save that as a data point in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import helperFunctions as hf\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "hf.setup()\n",
    "\n",
    "outputFolder = \"output_folder/\"\n",
    "outputFile = outputFolder + \"SuccessfulCallsUsedBandwidth.csv\"\n",
    "\n",
    "\n",
    "if not os.path.exists(outputFolder):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(outputFolder)\n",
    "   logging.info(f\"The directory \\\"{outputFolder}\\\" is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 15:10:38 INFO     scenarioDf 1 has 2474 records \n",
      "2023-02-05 15:57:59 INFO     scenarioDf 8 has 2402 records \n",
      "2023-02-05 16:43:45 INFO     scenarioDf 9 has 2356 records \n",
      "2023-02-05 17:28:59 INFO     scenarioDf 10 has 1784 records \n",
      "2023-02-05 18:02:03 INFO     scenarioDf 11 has 1398 records \n"
     ]
    }
   ],
   "source": [
    "callsDf = pd.read_csv(outputFolder + \"SuccessfulCallsStartAndEnd.csv\")\n",
    "\n",
    "df = pd.DataFrame(columns=[\"scenario\", \"client\", \"bps\"])\n",
    "\n",
    "scenarios = callsDf[\"scenario\"].unique()\n",
    "for scenario in scenarios:\n",
    "\n",
    "  scenarioDf = callsDf.loc[callsDf[\"scenario\"] == scenario]\n",
    "\n",
    "  logging.info(f\"scenarioDf {scenario} has {len(scenarioDf)} records\")\n",
    "\n",
    "  for index, row in scenarioDf.iterrows():\n",
    "\n",
    "    client = row[\"client\"]\n",
    "    start = row[\"start\"]\n",
    "    end = row[\"end\"]\n",
    "\n",
    "    # Get the bandwidth data for the client\n",
    "    instance = hf.getInstance(client)\n",
    "    if(instance == None):\n",
    "      logging.error(f\"Could not find instance for client {client}\")\n",
    "      continue\n",
    "\n",
    "    # Convert format and localtime to UTC\n",
    "    start = datetime.strptime(start, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    start = start - timedelta(hours=1)\n",
    "    if(start < datetime(2023, 1, 6)):\n",
    "      continue\n",
    "    start = start.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "    end = datetime.strptime(end, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    end = end - timedelta(hours=1)\n",
    "    end = end.strftime(\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "\n",
    "    query = \"/api/v1/query_range?query=irate(node_network_receive_bytes_total{instance=\\\"\"+ instance + \"\\\", device=\\\"eth0\\\"}[1m]) * 8&start=\" + start + \"&end=\" + end + \"&step=15s\"\n",
    "\n",
    "    url = \"http://localhost:9090\" + query\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers={}, data={})\n",
    "\n",
    "    \n",
    "\n",
    "    if(response.status_code == 200):\n",
    "      try:\n",
    "        values = json.loads(response.text)[\"data\"][\"result\"][0][\"values\"]\n",
    "        data = pd.DataFrame(values, columns=[\"time\", \"bps\"])\n",
    "        \n",
    "        # find average of bps\n",
    "        data[\"bps\"] = data[\"bps\"].astype(float)\n",
    "        average = data[\"bps\"].mean()\n",
    "\n",
    "        data = pd.DataFrame(columns=[\"scenario\", \"client\", \"bps\"], data=[[scenario, client, average]])\n",
    "        df = pd.concat([df, data], ignore_index=True)\n",
    "\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "\n",
    "df.to_csv(outputFile, index=False, mode=\"w\", header=True)\n",
    "\n",
    "\n",
    "      \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n",
     "\n"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "735cbb64c6f33b2d3af11b1f5c3709c6b8b8827e91f2b991e330f5d3f3bd728b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
