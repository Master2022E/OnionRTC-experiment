{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Successful calls start and end times\n",
    "\n",
    "Find all the start and end times for each of the successful calls in the scenarios 1, 8, 9, 10, 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import helperFunctions as hf\n",
    "import numpy as np\n",
    "\n",
    "hf.setup()\n",
    "\n",
    "outputFolder = \"output_folder/\"\n",
    "outputFile = outputFolder + \"SuccessfulCallsStartAndEnd.csv\"\n",
    "\n",
    "client = MongoClient(hf.getConnectionString())\n",
    "database=client[\"observertc-reports\"]\n",
    "calls=database[\"calls\"]\n",
    "\n",
    "if not os.path.exists(outputFolder):\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(outputFolder)\n",
    "   logging.info(f\"The directory \\\"{outputFolder}\\\" is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 12:15:04 INFO     Shape of uniqueCallsDf: (19222, 7) \n",
      "2023-02-05 12:15:04 INFO     Shape of successful calls: (19064, 7) \n",
      "2023-02-05 12:15:04 INFO     Starting on scenario 1, alice: c1-Normal, bob: d1-Normal \n",
      "2023-02-05 12:19:02 INFO     Starting on scenario 8, alice: c1-Normal, bob: d3-TorEurope \n",
      "2023-02-05 12:22:36 INFO     Starting on scenario 9, alice: c3-TorEurope, bob: d1-Normal \n",
      "2023-02-05 12:26:03 INFO     Starting on scenario 10, alice: c1-Normal, bob: d4-TorScandinavia \n",
      "2023-02-05 12:28:38 INFO     Starting on scenario 11, alice: c4-TorScandinavia, bob: d1-Normal \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"scenario\", \"client\", \"start\", \"end\"])\n",
    "\n",
    "uniqueCallsDf = pd.read_csv(outputFolder + \"UniqueCallsAndOutcomes.csv\")\n",
    "\n",
    "logging.info(f\"Shape of uniqueCallsDf: {uniqueCallsDf.shape}\")\n",
    "\n",
    "# filter for calls with state success\n",
    "successCallsDf = uniqueCallsDf.loc[uniqueCallsDf[\"logging_type\"] == \"COMMAND_SESSION_SUCCESS\"]\n",
    "\n",
    "logging.info(f\"Shape of successful calls: {successCallsDf.shape}\")\n",
    "\n",
    "for i in [1, 8, 9, 10, 11]:\n",
    "\n",
    "  s = hf.scenarios[i-1][\"scenario\"]\n",
    "  a = hf.scenarios[i-1][\"alice\"]\n",
    "  b = hf.scenarios[i-1][\"bob\"]\n",
    "  logging.info(f\"Starting on scenario {s}, alice: {a}, bob: {b}\")\n",
    "\n",
    "  # filter for calls with scenario_type s\n",
    "  scenarioCallsDf = successCallsDf.loc[successCallsDf[\"scenario_type\"] == s]\n",
    "\n",
    "  # get list of room_ids in scenarioCallsDf\n",
    "  roomIds = scenarioCallsDf[\"room_id\"].unique()\n",
    "\n",
    "  for roomId in roomIds:\n",
    "\n",
    "    aStart = calls.find_one({\"room_id\": str(roomId), \"client_username\": str(a), \"state\": \"call_in_progress\"})[\"timestamp\"]\n",
    "    aEnd = calls.find_one({\"room_id\": str(roomId), \"client_username\": str(a), \"state\": \"call_ended\"})[\"timestamp\"]\n",
    "    dataA = pd.DataFrame(columns=[\"scenario\", \"client\", \"start\", \"end\"], data=[[s, a, aStart, aEnd]])\n",
    "\n",
    "    bStart = calls.find_one({\"room_id\": str(roomId), \"client_username\": str(b), \"state\": \"call_in_progress\"})[\"timestamp\"]\n",
    "    bEnd = calls.find_one({\"room_id\": str(roomId), \"client_username\": str(b), \"state\": \"call_ended\"})[\"timestamp\"]\n",
    "    dataB = pd.DataFrame(columns=[\"scenario\", \"client\", \"start\", \"end\"], data=[[s, b, bStart, bEnd]])\n",
    "\n",
    "    df = pd.concat([df, dataA, dataB], ignore_index=True)\n",
    "\n",
    "df.to_csv(outputFile, index=False, header=True, encoding='utf-8', mode='w')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (tags/v3.9.1:1e5d33e, Dec  7 2020, 17:08:21) [MSC v.1927 64 bit (AMD64)]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n",
     "\n"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "735cbb64c6f33b2d3af11b1f5c3709c6b8b8827e91f2b991e330f5d3f3bd728b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
