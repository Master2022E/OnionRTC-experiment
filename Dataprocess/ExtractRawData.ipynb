{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extract Raw Data from ObserveRTC\n",
    "\n",
    "The output is a CSV file which will be appened to after each run.\n",
    "\n",
    "A local file will keep track of when the script was run last and only query data for that given time period.\n",
    "\n",
    "If there already exists a local data file, then it will load it and remove the latest duplicates. \n",
    "\n",
    "And append the newest entries. After this other data processing can happen by reading the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for records since: 1970-01-01 01:00:00\n",
      "Got data from database, converting to data frame\n",
      "Trying to read and load from rawData.csv\n",
      "size of new data:  (101606, 63)\n",
      "Saving timeOfCurrentQuery: 2022-12-22 13:57:17.606301 as epoch: 1671713837606\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "filename = \"output_folder/rawData.csv\"\n",
    "\n",
    "\n",
    "address = 'mongodb://{user}:{password}@{host}:{port}'.format(\n",
    "    user= os.getenv('MONGO_USER'),\n",
    "    password= os.getenv('MONGO_PASSWORD'),\n",
    "    host= \"localhost\",\n",
    "    port= os.getenv('MONGO_PORT')\n",
    ")\n",
    "client = MongoClient(address)\n",
    "database=client[\"observertc-reports\"]\n",
    "\n",
    "# the collection we want to query\n",
    "reportsDatabase = database.reports\n",
    "\n",
    "#read number from text file\n",
    "timeOfLastQuery = 0\n",
    "try:\n",
    "    with open(\"timeOfLastQuery.txt\", \"r\") as f:\n",
    "        timeOfLastQuery = int(f.read()) \n",
    "        print(\"Last run on:\", datetime.fromtimestamp(timeOfLastQuery/1000), \"going to search for new data 1 hour before this.\" )\n",
    "        timeOfLastQuery -= 1000 * 60 * 60 # 1 hour before last query\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Searching for records since:\", datetime.fromtimestamp(timeOfLastQuery/1000))\n",
    "\n",
    "timeOfCurrentQuery = datetime.now()\n",
    "cursor = reportsDatabase.find({\"type\": \"CLIENT_EXTENSION_DATA\", \n",
    "                                \"payload.extensionType\" : { \"$in\" : [\n",
    "                                    \"OUT_BOUND_RTC\", \n",
    "                                    \"IN_BOUND_RTC\", \n",
    "                                    \"REMOTE_OUT_BOUND_RTC\", \n",
    "                                    \"REMOTE_IN_BOUND_RTC\"]}, \n",
    "                                \"payload.timestamp\" : {\"$gt\": timeOfLastQuery}})\n",
    "\n",
    "print(\"Got data from database, converting to data frame\")\n",
    "dataSet = []\n",
    "for record in cursor:\n",
    "    data = {}\n",
    "    #append timestamp to data\n",
    "    data[\"timestamp\"] = record[\"payload\"][\"timestamp\"]\n",
    "    data[\"callId\"] = record[\"payload\"][\"callId\"]\n",
    "    data[\"roomId\"] = record[\"payload\"][\"roomId\"]\n",
    "    data[\"clientId\"] = record[\"payload\"][\"clientId\"]\n",
    "    data[\"userId\"] = record[\"payload\"][\"userId\"]\n",
    "    data[\"sampleSeq\"] = record[\"payload\"][\"sampleSeq\"]\n",
    "\n",
    "    a = json.loads(record[\"payload\"][\"payload\"])\n",
    "\n",
    "    # https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression\n",
    "    data = {**data, **a[\"stats\"]}\n",
    "\n",
    "    dataSet.append(data)\n",
    "\n",
    "\n",
    "newData = pd.DataFrame(dataSet)\n",
    "newData[\"callId\"]=newData[\"callId\"].astype(str)\n",
    "newData[\"roomId\"]=newData[\"roomId\"].astype(str)\n",
    "newData[\"clientId\"]=newData[\"clientId\"].astype(str)\n",
    "newData[\"userId\"]=newData[\"userId\"].astype(str)\n",
    "\n",
    "try:\n",
    "    print(\"Trying to read and load from\", filename)\n",
    "    oldData = pd.read_csv(filename)\n",
    "\n",
    "    oldData[\"callId\"]=oldData[\"callId\"].astype(str)\n",
    "    oldData[\"roomId\"]=oldData[\"roomId\"].astype(str)\n",
    "    oldData[\"clientId\"]=oldData[\"clientId\"].astype(str)\n",
    "    oldData[\"userId\"]=oldData[\"userId\"].astype(str)\n",
    "\n",
    "    print(\"size of old data: \", oldData.shape)\n",
    "    print(\"size of new data: \", newData.shape)\n",
    "\n",
    "    on = ['timestamp', 'callId', 'roomId', 'clientId', 'userId', 'sampleSeq',\n",
    "       'id', 'type', 'codecId', 'kind', 'mediaType', 'ssrc', 'bytesSent',\n",
    "       'packetsSent', 'headerBytesSent', 'nackCount', 'retransmittedBytesSent',\n",
    "       'retransmittedPacketsSent', 'remoteId', 'jitter', 'packetsLost',\n",
    "       'packetsReceived', 'fractionLost', 'localId', 'roundTripTime',\n",
    "       'roundTripTimeMeasurements', 'totalRoundTripTime', 'firCount',\n",
    "       'frameHeight', 'frameWidth', 'framesEncoded', 'framesSent',\n",
    "       'hugeFramesSent', 'pliCount', 'qpSum', 'totalEncodeTime',\n",
    "       'totalEncodedBytesTarget', 'packetsDiscarded', 'audioLevel',\n",
    "       'bytesReceived', 'concealedSamples', 'concealmentEvents',\n",
    "       'fecPacketsDiscarded', 'fecPacketsReceived', 'headerBytesReceived',\n",
    "       'insertedSamplesForDeceleration', 'jitterBufferDelay',\n",
    "       'jitterBufferEmittedCount', 'lastPacketReceivedTimestamp',\n",
    "       'removedSamplesForAcceleration', 'silentConcealedSamples',\n",
    "       'totalAudioEnergy', 'totalSamplesDuration', 'totalSamplesReceived',\n",
    "       'remoteTimestamp', 'discardedPackets', 'framesDecoded',\n",
    "       'framesPerSecond', 'framesReceived', 'totalDecodeTime',\n",
    "       'totalInterFrameDelay', 'totalProcessingDelay',\n",
    "       'totalSquaredInterFrameDelay']\n",
    "    diff =pd.merge(oldData,newData[on], indicator=True, how='right', on=on).query('_merge==\"right_only\"').drop('_merge', axis=1)\n",
    "\n",
    "    print(\"size of diff: \", diff.shape)\n",
    "\n",
    "    # append diff to data.csv\n",
    "    diff.to_csv(filename, mode='a', header=False, index=False)\n",
    "except:\n",
    "    print(\"size of new data: \", newData.shape)\n",
    "    newData.to_csv(filename, mode='w', header=True, index=False)\n",
    "    \n",
    "# save timeOfQuery to a file as epoch\n",
    "with open(\"timeOfLastQuery.txt\", \"w\") as f:\n",
    "    print(\"Saving timeOfCurrentQuery:\", timeOfCurrentQuery, \"as epoch:\", int(timeOfCurrentQuery.timestamp() * 1000))\n",
    "    f.write(str(int(timeOfCurrentQuery.timestamp() * 1000)))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n",
     "\n"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
