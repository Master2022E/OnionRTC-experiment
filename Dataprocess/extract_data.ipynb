{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Extract data from ObserveRTC\n",
    "\n",
    "The output is a CSV file which will be appened to after each run.\n",
    "\n",
    "A local file will keep track of when the script was run last and only query data for that given time period.\n",
    "\n",
    "If there already exists a local data file, then it will load it and remove the latest duplicates. \n",
    "\n",
    "And append the newest entries. After this other data processing can happen by reading the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\jtt\\anaconda3\\lib\\site-packages (4.3.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\jtt\\anaconda3\\lib\\site-packages (from pymongo) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jtt\\anaconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\jtt\\anaconda3\\lib\\site-packages (from pandas) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jtt\\anaconda3\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\jtt\\anaconda3\\lib\\site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jtt\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymongo\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "size of old data:  (7134, 63)\n",
      "size of new data:  (7134, 63)\n",
      "oldData:  (7134, 63)  newData:  (7134, 63) diff:  (0, 63)\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "address = 'mongodb://{user}:{password}@{host}:{port}'.format(\n",
    "    user= os.getenv('MONGO_USER'),\n",
    "    password= os.getenv('MONGO_PASSWORD'),\n",
    "    host= os.getenv('MONGO_HOST'),\n",
    "    port= os.getenv('MONGO_PORT')\n",
    ")\n",
    "client = MongoClient(address)\n",
    "database=client[\"observertc-reports\"]\n",
    "\n",
    "# the collection we want to query\n",
    "reportsDatabase = database.reports\n",
    "\n",
    "#read number from text file\n",
    "last_id = 0\n",
    "try:\n",
    "    with open(\"last_id.txt\", \"r\") as f:\n",
    "        last_id = int(f.read())\n",
    "except:\n",
    "    pass\n",
    "\n",
    "timeOfQuery = datetime.now()\n",
    "print(last_id)\n",
    "\n",
    "cursor = reportsDatabase.find({\"type\": \"CLIENT_EXTENSION_DATA\", \n",
    "                                \"payload.extensionType\" : { \"$in\" : [\n",
    "                                    \"OUT_BOUND_RTC\", \n",
    "                                    \"IN_BOUND_RTC\", \n",
    "                                    \"REMOTE_OUT_BOUND_RTC\", \n",
    "                                    \"REMOTE_IN_BOUND_RTC\"]}, \n",
    "                                \"payload.timestamp\" : {\"$gt\": 1667994458489},\n",
    "                                \"payload.roomId\" : \"5553563\"  })\n",
    "\n",
    "\n",
    "dataSet = []\n",
    "for record in cursor:\n",
    "    data = {}\n",
    "    #append timestamp to data\n",
    "    data[\"timestamp\"] = record[\"payload\"][\"timestamp\"]\n",
    "    data[\"callId\"] = record[\"payload\"][\"callId\"]\n",
    "    data[\"roomId\"] = record[\"payload\"][\"roomId\"]\n",
    "    data[\"clientId\"] = record[\"payload\"][\"clientId\"]\n",
    "    data[\"userId\"] = record[\"payload\"][\"userId\"]\n",
    "    data[\"sampleSeq\"] = record[\"payload\"][\"sampleSeq\"]\n",
    "\n",
    "    a = json.loads(record[\"payload\"][\"payload\"])\n",
    "\n",
    "    # https://stackoverflow.com/questions/38987/how-do-i-merge-two-dictionaries-in-a-single-expression\n",
    "    data = {**data, **a[\"stats\"]}\n",
    "\n",
    "    dataSet.append(data)\n",
    "\n",
    "#outBound = sorted(outBound, key=lambda k: k['timestamp'])\n",
    "\n",
    "newData = pd.DataFrame(dataSet)\n",
    "newData[\"callId\"]=newData[\"callId\"].astype(str)\n",
    "newData[\"roomId\"]=newData[\"roomId\"].astype(str)\n",
    "newData[\"clientId\"]=newData[\"clientId\"].astype(str)\n",
    "newData[\"userId\"]=newData[\"userId\"].astype(str)\n",
    "\n",
    "#df.to_csv(\"data.csv\", index=False)\n",
    "\n",
    "\n",
    "# Append data to existing csv but skip duplicates\n",
    "# https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe\n",
    "oldData = pd.read_csv(\"data.csv\")\n",
    "\n",
    "oldData[\"callId\"]=oldData[\"callId\"].astype(str)\n",
    "oldData[\"roomId\"]=oldData[\"roomId\"].astype(str)\n",
    "oldData[\"clientId\"]=oldData[\"clientId\"].astype(str)\n",
    "oldData[\"userId\"]=oldData[\"userId\"].astype(str)\n",
    "\n",
    "print(\"size of old data: \", oldData.shape)\n",
    "print(\"size of new data: \", newData.shape)\n",
    "\n",
    "on = ['timestamp', 'callId', 'roomId', 'clientId', 'userId', 'type', 'sampleSeq', 'kind']\n",
    "diff =pd.merge(oldData,newData[on], indicator=True, how='right', on=on).query('_merge==\"right_only\"').drop('_merge', axis=1)\n",
    "\n",
    "print(\"oldData: \", oldData.shape, \" newData: \", newData.shape, \"diff: \", diff.shape)\n",
    "\n",
    "# append diff to data.csv\n",
    "diff.to_csv(\"data.csv\", mode='a', header=False, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n",
     "\n",
     "\n",
     "\n"
    ]
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "7bbccfae9e3dad4e14e338663d01269f0f0813dc97e5ae4055738d53b62925ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
